# An√°lisis de Sentimiento en YouTube con Deep Learning (BERT) ü§ñüìä

Este proyecto implementa un pipeline completo de Ciencia de Datos para extraer, procesar y analizar el sentimiento de comentarios en YouTube. Utilizamos el modelo **BETO** (BERT adaptado al espa√±ol) para obtener una clasificaci√≥n precisa que entiende el contexto, el sarcasmo y las negaciones.

## Hecho por
**Franco Corti** *Data Analyst & Estudiante de Licenciatura en Ciencia de Datos.  

## üõ†Ô∏è Tecnolog√≠as y Librer√≠as
* **Extracci√≥n:** `google-api-python-client` (YouTube Data API v3).
* **Procesamiento de Lenguaje Natural (NLP):** `pysentimiento` (Transformer BETO), `re` (Regex).
* **An√°lisis de Datos:** `pandas`, `numpy`.
* **Visualizaci√≥n:** `matplotlib`, `seaborn`, `wordcloud`.
* **Entorno:** `python-dotenv`.

## üß† Paso a paso del desarrollo 

### 1. Extracci√≥n e Ingenier√≠a de Datos (ETL)
Se desarroll√≥ un script para conectarse a la API de YouTube, extrayendo comentarios crudos y metadatos asociados. 

### 2. Preprocesamiento "Suave" vs. "Agresivo"
* **Suave (Para BERT):** Se dise√±√≥ una limpieza que elimina URLs y ruido innecesario pero conserva emojis, signos de exclamaci√≥n y may√∫sculas, permitiendo que el Transformer capte la intensidad emocional.
* **Agresiva (Para Nubes de Palabras):** Se normaliz√≥ el texto a min√∫sculas y se aplic√≥ una lista personalizada de **Stopwords** para eliminar palabras vac√≠as de significado t√©cnico.

### 3. Modelado con Deep Learning
Se integr√≥ el modelo de lenguaje **BETO**. A diferencia de los m√©todos basados en diccionarios, este modelo analiza la frase completa. El script calcula:
* **Sentimiento:** Clasificaci√≥n en Positivo, Negativo o Neutral.
* **Confianza:** Un valor probabil√≠stico (0.0 a 1.0) que indica la seguridad de la predicci√≥n de la IA.

### 4. Visualizaci√≥n de Resultados
Se crearon tres tipos de reportes visuales:
* **Gr√°ficos de Barras:** Para la distribuci√≥n general de sentimientos.
 ![Grafico de barras](output/reporte_grafico_barras.png)
* **Histogramas de Confianza:** Para validar la robustez del modelo y detectar ambig√ºedades.
 ![Histograma de Confianza](output/histograma_confianza_bert.png)
* **WordClouds:** Para el an√°lisis sem√°ntico de temas recurrentes por categor√≠a.
 ![Nubes de Sentimiento](output/nubes_sentimiento_final.png)

## üìÅ Estructura de Carpetas
- `src/`: Scripts principales (`extraer_youtube.py`, `analizar_bert.py`, etc.).
- `data/`: Archivos CSV intermedios y finales.
- `output/`: Reportes gr√°ficos generados.
- `requirements.txt`: Lista de dependencias del entorno.

## üîß Pasos para Correr el Proyecto

### 1. Clonar y Configurar Entorno
```bash
git clone [https://github.com/FrancoCorti/analisis-sentimiento-youtube-bert.git](https://github.com/FrancoCorti/analisis-sentimiento-youtube-bert.git)
cd analisis-sentimiento-youtube-bert
python -m venv venv
# Activar entorno (Windows)
.\venv\Scripts\activate
# Instalar librer√≠as
pip install -r requirements.txt
```

### 2. Configuracion de Credenciales
Crea un archivo llamado .env en la ra√≠z del proyecto (este archivo est√° ignorado por Git por seguridad). Agrega tu clave de API de Google Cloud de la siguiente manera:
```YOUTUBE_API_KEY=Tu_Clave_De_Google_Cloud_Aqui```

### 3. Orden de ejecucion
Para procesar los datos correctamente, ejecut√° los scripts desde la terminal en el siguiente orden:
* **python src/extraer_youtube.py**: Descarga los comentarios del video seleccionado.
* **python src/limpiar_datos.py**: Aplica la limpieza necesaria para el modelo Transformer.
* **python src/analizar_bert.py**: Realiza el an√°lisis de sentimiento y calcula la confianza.
* **python src/nube_palabras.py**: Genera las nubes de palabras por categor√≠a de sentimiento.
* **python src/graficar_confianza.py**: Crea el histograma de validaci√≥n estad√≠stica.


